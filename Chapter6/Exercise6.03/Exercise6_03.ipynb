{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import random\n",
    "\n",
    "# Load the Data\n",
    "X = pd.read_csv(\"../data/aps_failure_training_feats.csv\")\n",
    "y = pd.read_csv(\"../data/aps_failure_training_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 42\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.20, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "# Transform the training data\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train,columns=X_test.columns)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test=sc.transform(X_test)\n",
    "X_test=pd.DataFrame(X_test,columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the relevant Keras libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.set_seed(seed)\n",
    "model = Sequential()\n",
    "\n",
    "# Add the hidden dense layers and with dropout Layer\n",
    "model.add(Dense(units=64, activation='relu', kernel_initializer='uniform', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(units=32, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dropout(rate=0.4))\n",
    "model.add(Dense(units=16, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(units=8, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=4, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "# Add Output Dense Layer\n",
    "model.add(Dense(units=1, activation='sigmoid', kernel_initializer='uniform'))\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38400 samples, validate on 9600 samples\n",
      "Epoch 1/100\n",
      "38400/38400 [==============================] - 7s 180us/step - loss: 0.0863 - accuracy: 0.9832 - val_loss: 0.0384 - val_accuracy: 0.9842\n",
      "Epoch 2/100\n",
      "38400/38400 [==============================] - 5s 131us/step - loss: 0.0414 - accuracy: 0.9834 - val_loss: 0.0340 - val_accuracy: 0.9842\n",
      "Epoch 3/100\n",
      "38400/38400 [==============================] - 6s 148us/step - loss: 0.0369 - accuracy: 0.9834 - val_loss: 0.0328 - val_accuracy: 0.9842\n",
      "Epoch 4/100\n",
      "38400/38400 [==============================] - 5s 138us/step - loss: 0.0339 - accuracy: 0.9840 - val_loss: 0.0322 - val_accuracy: 0.9897\n",
      "Epoch 5/100\n",
      "38400/38400 [==============================] - 5s 139us/step - loss: 0.0365 - accuracy: 0.9889 - val_loss: 0.0321 - val_accuracy: 0.9887\n",
      "Epoch 6/100\n",
      "38400/38400 [==============================] - 5s 133us/step - loss: 0.0334 - accuracy: 0.9898 - val_loss: 0.0290 - val_accuracy: 0.9912\n",
      "Epoch 7/100\n",
      "38400/38400 [==============================] - 7s 174us/step - loss: 0.0320 - accuracy: 0.9904 - val_loss: 0.0284 - val_accuracy: 0.9910\n",
      "Epoch 8/100\n",
      "38400/38400 [==============================] - 5s 137us/step - loss: 0.0332 - accuracy: 0.9911 - val_loss: 0.0314 - val_accuracy: 0.99162s -\n",
      "Epoch 9/100\n",
      "38400/38400 [==============================] - 5s 132us/step - loss: 0.0319 - accuracy: 0.9907 - val_loss: 0.0329 - val_accuracy: 0.9900\n",
      "Epoch 10/100\n",
      "38400/38400 [==============================] - 5s 141us/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.0317 - val_accuracy: 0.9906\n",
      "Epoch 11/100\n",
      "38400/38400 [==============================] - 5s 141us/step - loss: 0.0313 - accuracy: 0.9914 - val_loss: 0.0290 - val_accuracy: 0.9918\n",
      "Epoch 12/100\n",
      "38400/38400 [==============================] - 5s 140us/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 0.0295 - val_accuracy: 0.9911 - ETA: 1s - loss:\n",
      "Epoch 13/100\n",
      "38400/38400 [==============================] - 5s 136us/step - loss: 0.0280 - accuracy: 0.9920 - val_loss: 0.0297 - val_accuracy: 0.9919\n",
      "Epoch 14/100\n",
      "38400/38400 [==============================] - 5s 129us/step - loss: 0.0285 - accuracy: 0.9918 - val_loss: 0.0311 - val_accuracy: 0.9919\n",
      "Epoch 15/100\n",
      "38400/38400 [==============================] - 5s 139us/step - loss: 0.0290 - accuracy: 0.9917 - val_loss: 0.0302 - val_accuracy: 0.9918\n",
      "Epoch 16/100\n",
      "38400/38400 [==============================] - 5s 137us/step - loss: 0.0268 - accuracy: 0.9922 - val_loss: 0.0306 - val_accuracy: 0.9920\n",
      "Epoch 17/100\n",
      "38400/38400 [==============================] - 5s 142us/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 0.0322 - val_accuracy: 0.9920\n",
      "Epoch 18/100\n",
      "38400/38400 [==============================] - 6s 155us/step - loss: 0.0268 - accuracy: 0.9926 - val_loss: 0.0282 - val_accuracy: 0.9910\n",
      "Epoch 19/100\n",
      "38400/38400 [==============================] - 5s 128us/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.0318 - val_accuracy: 0.9927\n",
      "Epoch 20/100\n",
      "38400/38400 [==============================] - 6s 151us/step - loss: 0.0276 - accuracy: 0.9921 - val_loss: 0.0448 - val_accuracy: 0.9923\n",
      "Epoch 21/100\n",
      "38400/38400 [==============================] - 7s 172us/step - loss: 0.0261 - accuracy: 0.9922 - val_loss: 0.0323 - val_accuracy: 0.9919\n",
      "Epoch 22/100\n",
      "38400/38400 [==============================] - 7s 181us/step - loss: 0.0273 - accuracy: 0.9922 - val_loss: 0.0306 - val_accuracy: 0.9916\n",
      "Epoch 23/100\n",
      "38400/38400 [==============================] - 5s 132us/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.0388 - val_accuracy: 0.9911\n",
      "Epoch 24/100\n",
      "38400/38400 [==============================] - 6s 144us/step - loss: 0.0263 - accuracy: 0.9926 - val_loss: 0.0367 - val_accuracy: 0.9912\n",
      "Epoch 25/100\n",
      "38400/38400 [==============================] - 5s 131us/step - loss: 0.0258 - accuracy: 0.9928 - val_loss: 0.0325 - val_accuracy: 0.9919\n",
      "Epoch 26/100\n",
      "38400/38400 [==============================] - 5s 138us/step - loss: 0.0264 - accuracy: 0.9930 - val_loss: 0.0317 - val_accuracy: 0.9915\n",
      "Epoch 27/100\n",
      "38400/38400 [==============================] - 5s 131us/step - loss: 0.0253 - accuracy: 0.9928 - val_loss: 0.0344 - val_accuracy: 0.9924\n",
      "Epoch 28/100\n",
      "38400/38400 [==============================] - 5s 133us/step - loss: 0.0272 - accuracy: 0.9928 - val_loss: 0.0384 - val_accuracy: 0.9919\n",
      "Epoch 29/100\n",
      "38400/38400 [==============================] - 5s 136us/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 0.0339 - val_accuracy: 0.9926\n",
      "Epoch 30/100\n",
      "38400/38400 [==============================] - 5s 127us/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.0276 - val_accuracy: 0.9927\n",
      "Epoch 31/100\n",
      "38400/38400 [==============================] - 5s 126us/step - loss: 0.0242 - accuracy: 0.9930 - val_loss: 0.0494 - val_accuracy: 0.9923\n",
      "Epoch 32/100\n",
      "38400/38400 [==============================] - 5s 134us/step - loss: 0.0255 - accuracy: 0.9930 - val_loss: 0.0354 - val_accuracy: 0.9915\n",
      "Epoch 33/100\n",
      "38400/38400 [==============================] - 6s 156us/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.0375 - val_accuracy: 0.9928\n",
      "Epoch 34/100\n",
      "38400/38400 [==============================] - 6s 146us/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.0282 - val_accuracy: 0.9920\n",
      "Epoch 35/100\n",
      "38400/38400 [==============================] - 6s 156us/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.0343 - val_accuracy: 0.9925\n",
      "Epoch 36/100\n",
      "38400/38400 [==============================] - 5s 141us/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 0.0342 - val_accuracy: 0.9931\n",
      "Epoch 37/100\n",
      "38400/38400 [==============================] - 6s 144us/step - loss: 0.0238 - accuracy: 0.9939 - val_loss: 0.0309 - val_accuracy: 0.9925\n",
      "Epoch 38/100\n",
      "38400/38400 [==============================] - 5s 136us/step - loss: 0.0241 - accuracy: 0.9935 - val_loss: 0.0408 - val_accuracy: 0.9931\n",
      "Epoch 39/100\n",
      "38400/38400 [==============================] - 5s 129us/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 0.0329 - val_accuracy: 0.9918\n",
      "Epoch 40/100\n",
      "38400/38400 [==============================] - 5s 141us/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 0.0335 - val_accuracy: 0.9933\n",
      "Epoch 41/100\n",
      "38400/38400 [==============================] - 5s 141us/step - loss: 0.0252 - accuracy: 0.9932 - val_loss: 0.0392 - val_accuracy: 0.9930\n",
      "Epoch 42/100\n",
      "38400/38400 [==============================] - 6s 145us/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 0.0356 - val_accuracy: 0.9928\n",
      "Epoch 43/100\n",
      "38400/38400 [==============================] - 6s 146us/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 0.0282 - val_accuracy: 0.9927\n",
      "Epoch 44/100\n",
      "38400/38400 [==============================] - 6s 165us/step - loss: 0.0252 - accuracy: 0.9937 - val_loss: 0.0378 - val_accuracy: 0.9930\n",
      "Epoch 45/100\n",
      "38400/38400 [==============================] - 5s 142us/step - loss: 0.0235 - accuracy: 0.9943 - val_loss: 0.0500 - val_accuracy: 0.9916\n",
      "Epoch 46/100\n",
      "38400/38400 [==============================] - 5s 134us/step - loss: 0.0237 - accuracy: 0.9939 - val_loss: 0.0311 - val_accuracy: 0.9930\n",
      "Epoch 47/100\n",
      "38400/38400 [==============================] - 5s 130us/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.0327 - val_accuracy: 0.9928\n",
      "Epoch 48/100\n",
      "38400/38400 [==============================] - 5s 132us/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 0.0368 - val_accuracy: 0.9930\n",
      "Epoch 49/100\n",
      "38400/38400 [==============================] - 5s 131us/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0351 - val_accuracy: 0.9929\n",
      "Epoch 50/100\n",
      "38400/38400 [==============================] - 5s 128us/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.0386 - val_accuracy: 0.9929\n",
      "Epoch 51/100\n",
      "38400/38400 [==============================] - 6s 159us/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.0341 - val_accuracy: 0.9930\n",
      "Epoch 52/100\n",
      "38400/38400 [==============================] - 6s 159us/step - loss: 0.0240 - accuracy: 0.9940 - val_loss: 0.0454 - val_accuracy: 0.9930\n",
      "Epoch 53/100\n",
      "38400/38400 [==============================] - 6s 150us/step - loss: 0.0221 - accuracy: 0.9945 - val_loss: 0.0299 - val_accuracy: 0.9925\n",
      "Epoch 54/100\n",
      "38400/38400 [==============================] - 5s 135us/step - loss: 0.0237 - accuracy: 0.9940 - val_loss: 0.0472 - val_accuracy: 0.9925\n",
      "Epoch 55/100\n",
      "38400/38400 [==============================] - 6s 152us/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 0.0414 - val_accuracy: 0.9925\n",
      "Epoch 56/100\n",
      "38400/38400 [==============================] - 5s 138us/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.0426 - val_accuracy: 0.9933\n",
      "Epoch 57/100\n",
      "38400/38400 [==============================] - 5s 138us/step - loss: 0.0221 - accuracy: 0.9947 - val_loss: 0.0478 - val_accuracy: 0.9926\n",
      "Epoch 58/100\n",
      "38400/38400 [==============================] - 5s 128us/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.0334 - val_accuracy: 0.9920\n",
      "Epoch 59/100\n",
      "38400/38400 [==============================] - 5s 135us/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.0396 - val_accuracy: 0.9925\n",
      "Epoch 60/100\n",
      "38400/38400 [==============================] - 6s 154us/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.0407 - val_accuracy: 0.9921\n",
      "Epoch 61/100\n",
      "38400/38400 [==============================] - 5s 131us/step - loss: 0.0211 - accuracy: 0.9946 - val_loss: 0.0312 - val_accuracy: 0.9911\n",
      "Epoch 62/100\n",
      "38400/38400 [==============================] - 5s 117us/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.0408 - val_accuracy: 0.9921\n",
      "Epoch 63/100\n",
      "38400/38400 [==============================] - 5s 122us/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.0444 - val_accuracy: 0.9924\n",
      "Epoch 64/100\n",
      "38400/38400 [==============================] - 5s 129us/step - loss: 0.0213 - accuracy: 0.9946 - val_loss: 0.0676 - val_accuracy: 0.9922\n",
      "Epoch 65/100\n",
      "38400/38400 [==============================] - 6s 150us/step - loss: 0.0220 - accuracy: 0.9946 - val_loss: 0.0467 - val_accuracy: 0.9921\n",
      "Epoch 66/100\n",
      "38400/38400 [==============================] - 6s 151us/step - loss: 0.0218 - accuracy: 0.9943 - val_loss: 0.0347 - val_accuracy: 0.9926\n",
      "Epoch 67/100\n",
      "38400/38400 [==============================] - 5s 131us/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 0.0369 - val_accuracy: 0.9918\n",
      "Epoch 68/100\n",
      "38400/38400 [==============================] - 6s 166us/step - loss: 0.0225 - accuracy: 0.9945 - val_loss: 0.0500 - val_accuracy: 0.9921\n",
      "Epoch 69/100\n",
      "38400/38400 [==============================] - 7s 189us/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.0505 - val_accuracy: 0.9925\n",
      "Epoch 70/100\n",
      "38400/38400 [==============================] - 6s 165us/step - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.0465 - val_accuracy: 0.9923\n",
      "Epoch 71/100\n",
      "38400/38400 [==============================] - 6s 151us/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.0522 - val_accuracy: 0.9924\n",
      "Epoch 72/100\n",
      "38400/38400 [==============================] - 6s 149us/step - loss: 0.0205 - accuracy: 0.9946 - val_loss: 0.0393 - val_accuracy: 0.9919\n",
      "Epoch 73/100\n",
      "38400/38400 [==============================] - 5s 137us/step - loss: 0.0223 - accuracy: 0.9943 - val_loss: 0.0383 - val_accuracy: 0.9915\n",
      "Epoch 74/100\n",
      "38400/38400 [==============================] - 5s 141us/step - loss: 0.0217 - accuracy: 0.9944 - val_loss: 0.0515 - val_accuracy: 0.9923\n",
      "Epoch 75/100\n",
      "38400/38400 [==============================] - 5s 142us/step - loss: 0.0211 - accuracy: 0.9947 - val_loss: 0.0508 - val_accuracy: 0.9930\n",
      "Epoch 76/100\n",
      "38400/38400 [==============================] - 5s 131us/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.0589 - val_accuracy: 0.9924\n",
      "Epoch 77/100\n",
      "38400/38400 [==============================] - 5s 123us/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.0354 - val_accuracy: 0.9921\n",
      "Epoch 78/100\n",
      "38400/38400 [==============================] - 5s 134us/step - loss: 0.0228 - accuracy: 0.9943 - val_loss: 0.0558 - val_accuracy: 0.9930\n",
      "Epoch 79/100\n",
      "38400/38400 [==============================] - 5s 125us/step - loss: 0.0212 - accuracy: 0.9948 - val_loss: 0.0429 - val_accuracy: 0.9929\n",
      "Epoch 80/100\n",
      "38400/38400 [==============================] - 5s 132us/step - loss: 0.0213 - accuracy: 0.9947 - val_loss: 0.0455 - val_accuracy: 0.9916\n",
      "Epoch 81/100\n",
      "38400/38400 [==============================] - 5s 129us/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.0633 - val_accuracy: 0.9926\n",
      "Epoch 82/100\n",
      "38400/38400 [==============================] - 5s 129us/step - loss: 0.0219 - accuracy: 0.9947 - val_loss: 0.0306 - val_accuracy: 0.9918\n",
      "Epoch 83/100\n",
      "38400/38400 [==============================] - 5s 131us/step - loss: 0.0200 - accuracy: 0.9946 - val_loss: 0.0438 - val_accuracy: 0.9927\n",
      "Epoch 84/100\n",
      "38400/38400 [==============================] - 5s 126us/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.0435 - val_accuracy: 0.9923\n",
      "Epoch 85/100\n",
      "38400/38400 [==============================] - 5s 127us/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.0566 - val_accuracy: 0.9920\n",
      "Epoch 86/100\n",
      "38400/38400 [==============================] - 5s 127us/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 0.0396 - val_accuracy: 0.9915\n",
      "Epoch 87/100\n",
      "38400/38400 [==============================] - 5s 127us/step - loss: 0.0210 - accuracy: 0.9948 - val_loss: 0.0496 - val_accuracy: 0.9920\n",
      "Epoch 88/100\n",
      "38400/38400 [==============================] - 5s 131us/step - loss: 0.0203 - accuracy: 0.9952 - val_loss: 0.0493 - val_accuracy: 0.9923\n",
      "Epoch 89/100\n",
      "38400/38400 [==============================] - 5s 129us/step - loss: 0.0216 - accuracy: 0.9947 - val_loss: 0.0433 - val_accuracy: 0.9915\n",
      "Epoch 90/100\n",
      "38400/38400 [==============================] - 5s 123us/step - loss: 0.0228 - accuracy: 0.9946 - val_loss: 0.0376 - val_accuracy: 0.9919\n",
      "Epoch 91/100\n",
      "38400/38400 [==============================] - 5s 123us/step - loss: 0.0217 - accuracy: 0.9948 - val_loss: 0.0553 - val_accuracy: 0.9924\n",
      "Epoch 92/100\n",
      "38400/38400 [==============================] - 5s 122us/step - loss: 0.0193 - accuracy: 0.9952 - val_loss: 0.0489 - val_accuracy: 0.9918\n",
      "Epoch 93/100\n",
      "38400/38400 [==============================] - 5s 125us/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 0.0348 - val_accuracy: 0.9903\n",
      "Epoch 94/100\n",
      "38400/38400 [==============================] - 5s 128us/step - loss: 0.0202 - accuracy: 0.9949 - val_loss: 0.0712 - val_accuracy: 0.9923\n",
      "Epoch 95/100\n",
      "38400/38400 [==============================] - 5s 124us/step - loss: 0.0205 - accuracy: 0.9952 - val_loss: 0.0549 - val_accuracy: 0.9915\n",
      "Epoch 96/100\n",
      "38400/38400 [==============================] - 5s 123us/step - loss: 0.0193 - accuracy: 0.9951 - val_loss: 0.0441 - val_accuracy: 0.9916\n",
      "Epoch 97/100\n",
      "38400/38400 [==============================] - 5s 125us/step - loss: 0.0196 - accuracy: 0.9951 - val_loss: 0.0692 - val_accuracy: 0.9925\n",
      "Epoch 98/100\n",
      "38400/38400 [==============================] - 5s 125us/step - loss: 0.0204 - accuracy: 0.9950 - val_loss: 0.0639 - val_accuracy: 0.9923\n",
      "Epoch 99/100\n",
      "38400/38400 [==============================] - 5s 123us/step - loss: 0.0201 - accuracy: 0.9952 - val_loss: 0.0699 - val_accuracy: 0.9919\n",
      "Epoch 100/100\n",
      "38400/38400 [==============================] - 5s 123us/step - loss: 0.0203 - accuracy: 0.9946 - val_loss: 0.0612 - val_accuracy: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x15a259080>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=20, verbose=1, validation_split=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix & Derived Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11733    55]\n",
      " [   66   146]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred_class1 = y_pred > 0.5\n",
    "cm = confusion_matrix(y_test, y_pred_class1)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Negative\n",
    "TN = cm[0,0]\n",
    "\n",
    "# False Negative\n",
    "FN=cm[1,0]\n",
    "\n",
    "# False Positives\n",
    "FP = cm[0,1]\n",
    "\n",
    "# True Positives\n",
    "TP = cm[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.6887\n"
     ]
    }
   ],
   "source": [
    "# Calculating Sensitivity\n",
    "Sensitivity = TP / (TP + FN)\n",
    "print(f'Sensitivity: {Sensitivity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9953\n"
     ]
    }
   ],
   "source": [
    "# Calculating Specificity\n",
    "Specificity = TN / (TN + FP)\n",
    "print(f'Specificity: {Specificity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7264\n"
     ]
    }
   ],
   "source": [
    "# Precision\n",
    "Precision = TP / (TP + FP)\n",
    "print(f'Precision: {Precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate: 0.0047\n"
     ]
    }
   ],
   "source": [
    "# Calculate False positive rate\n",
    "False_Positive_rate = FP / (FP + TN)\n",
    "print(f'False positive rate: {False_Positive_rate:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class2 = y_pred > 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11723    65]\n",
      " [   63   149]]\n"
     ]
    }
   ],
   "source": [
    "cm=confusion_matrix(y_test,y_pred_class2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Negative\n",
    "TN = cm[0,0]\n",
    "\n",
    "# False Negative\n",
    "FN=cm[1,0]\n",
    "\n",
    "# False Positives\n",
    "FP = cm[0,1]\n",
    "\n",
    "# True Positives\n",
    "TP = cm[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.7028\n"
     ]
    }
   ],
   "source": [
    "# Calculating Sensitivity\n",
    "Sensitivity = TP / (TP + FN)\n",
    "print(f'Sensitivity: {Sensitivity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9945\n"
     ]
    }
   ],
   "source": [
    "# Calculating Specificity\n",
    "Specificity = TN / (TN + FP)\n",
    "print(f'Specificity: {Specificity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#histogram of class distribution\n",
    "plt.hist(y_pred_prob, bins=100)\n",
    "plt.title(\"Histogram of Predicted Probabilities\")\n",
    "plt.xlabel(\"Predicted Probabilities of APS failure\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
